{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Geeks for Geeks - Logistic Regression in Machine Learning](https://www.geeksforgeeks.org/understanding-logistic-regression/)\n",
    "\n",
    "[Scikit Learn - LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "[StatQuest: Logistic Regression](https://youtu.be/yIYKR4sgzI8?si=k2EGU-u74p-jecQW)\n",
    "\n",
    "[Google Developer Program](https://developers.google.com/machine-learning/crash-course/logistic-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Characteristics**\n",
    "\n",
    "- used for (often binary) classification \n",
    "- produces independent variables (features) to probability between $0$ and $1$\n",
    "- outcome should be discrete value (classes $0$ or $1$)\n",
    "- gives probabilistic values for each class\n",
    "- extension of linear regression\n",
    "- uses sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equations**\n",
    "$$z = b + w_1x_1 + w_2x_2 + \\cdots + w_nx_n = b + \\vec{w}^T\\vec{x}$$\n",
    "$$\\hat{y} = \\sigma(z)=\\frac{1}{1+e^{-z}}$$\n",
    "$$\\text{returns}\\, \\begin{cases}1&\\hat{y}\\geq0.5\\\\0&\\hat{y}<0.5\\end{cases}$$\n",
    "\n",
    "- $e^z$: odd, the ratio of the probability of favorable outcomes and that of unfavorable outcomes ($\\frac{p}{1-p}$)\n",
    "- $\\sigma$: probability ($p$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss Function**\n",
    "\n",
    "Binary Cross-Entropy Loss (Log Loss):\n",
    "$$\\ell(\\hat{y}_i,y_i) = -y_i\\log(\\hat{y}_i)-(1-y_i)\\log(1-\\hat{y}_i)$$\n",
    "$$J(\\vec{w},b)=-\\frac{1}{n}\\sum\\limits_{i=1}^{n}(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivatives**\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial\\ell}{\\partial \\hat{y}} &= -\\frac{y_i}{\\hat{y}_i}+\\frac{1-y_i}{1-\\hat{y}_i}\\\\\n",
    "    &=\\frac{\\hat{y}_i-y_i}{\\hat{y}_i(1-\\hat{y}_i)}\\\\\n",
    "    \\\\\n",
    "    \\frac{\\partial \\hat{y}}{\\partial z} &= \\frac{e^{-z}}{(1+e^{-z})^2}\\\\\n",
    "    &= \\frac{1}{1+e^{-z}}\\cdot\\left(1-\\frac{1}{1+e^{-z}}\\right)\\\\\n",
    "    &= \\hat{y}_i\\left(1-\\hat{y}_i\\right)\\\\\n",
    "    \\\\\n",
    "    \\frac{\\partial z}{\\partial \\vec{w}} &= \\vec{x}\\\\\n",
    "    \\frac{\\partial z}{\\partial b} &= 1\n",
    "\\end{align*}\n",
    "\n",
    "**Gradients**\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial J}{\\partial \\vec{w}}&=\\frac{1}{n}\\sum\\frac{\\partial\\ell}{\\partial \\vec{w}}\\\\\n",
    "    &=\\frac{1}{n}\\sum\\left(\\frac{\\partial\\ell}{\\partial \\hat{y}}\\cdot\\frac{\\partial \\hat{y}}{\\partial z}\\cdot\\frac{\\partial z}{\\partial \\vec{w}}\\right)\\\\\n",
    "    &=\\frac{1}{n}\\sum\\limits(\\hat{y}-y)\\vec{x}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial J}{\\partial b}&=\\frac{1}{n}\\sum\\frac{\\partial\\ell}{\\partial b}\\\\\n",
    "    &=\\frac{1}{n}\\sum\\left(\\frac{\\partial\\ell}{\\partial \\hat{y}}\\cdot\\frac{\\partial \\hat{y}}{\\partial z}\\cdot\\frac{\\partial z}{\\partial b}\\right)\\\\\n",
    "    &=\\frac{1}{n}\\sum\\limits(\\hat{y}-y)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter Update**\n",
    "\n",
    "$$\\vec{w}=\\vec{w}-\\alpha\\left(\\frac{1}{n}\\sum(y-\\hat{y})\\vec{x}\\right)$$\n",
    "$$b=b-\\alpha\\left(\\frac{1}{n}\\sum(y-\\hat{y})\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although multinomial logistic regression exists, only binomial model will be implemented."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
