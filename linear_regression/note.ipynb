{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Geeks for Geeks - Linear Regression in Machine Learning](https://www.geeksforgeeks.org/ml-linear-regression/)\n",
    "\n",
    "[Scikit Learn - LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics\n",
    "\n",
    "- supervised learning algorithm for regression tasks\n",
    "- linear relationship between inputs and outputs\n",
    "- finds line of best fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "1. Linearity: the relationship between features and target is linear\n",
    "2. Independence: observations are independent of each other\n",
    "3. Homoscedasticity: constant variance in residuals\n",
    "4. Normality of Residuals: residuals should be normally distributed\n",
    "5. No Perfect Multicollinearity: features should not be highly correlated\n",
    "\n",
    "The model performance may decrese if assumptions are not satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs & Outputs\n",
    "\n",
    "- **Input**: feature matrix $X$ of shape $(n_{\\text{samples}}, n_{\\text{features}})$\n",
    "- **Output**: target variable $y$ of shape $(n_{\\text{samples}},)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "- $\\vec{w}$: weights, $(n_\\text{features},)$\n",
    "- $b$: bias, float\n",
    "\n",
    "- **Hyperparameters**:\n",
    "    - $\\alpha$: learning rate\n",
    "    - number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime\n",
    "\n",
    "- **Training**: $O(nd)$ per epoch\n",
    "- **Inference**: $O(nd)$\n",
    "\n",
    "where $n=$ number of samples, $d=$ number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros & Cons\n",
    "\n",
    "- Pros:\n",
    "    - Simple and Interpretable: easy to implement and explain\n",
    "    - Works well for linearly separable data\n",
    "    - Used as a baseline: often used before trying complex models\n",
    "- Cons:\n",
    "    - Sensitive to outliers: large errors from outliers can skew predictions\n",
    "    - Assumes linear relationship: fails if data is non-linear\n",
    "    - Multicollinearity issues: highly correlated features can lead to unstable weights\n",
    "    - Not great for complex data: can underfit high dimensional or non linear data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "- Predicting house prices\n",
    "- Forecasting stock trends\n",
    "- Medical risk assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Equation\n",
    "$$y=b+w_1x_1+w_2x_2+\\cdots+w_nx_n=b+\\vec{w}\\cdot\\vec{x}$$\n",
    "$$\\vec{y}=X\\vec{w}+\\vec{b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "Mean Squared Error:\n",
    "$$\\ell(\\hat{y}_i,y_i)=(\\hat{y}_i-y_i)^2$$\n",
    "$$J(\\vec{w},b)=\\frac{1}{n}\\sum\\limits_{i=1}^{n}(\\hat{y}_i-y_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial J}{\\partial \\vec{w}}&=\\frac{\\partial}{\\partial \\vec{w}}\\left(\\frac{1}{n}\\sum(\\hat{y}-y)^2\\right)\\\\\n",
    "    &=\\frac{1}{n}\\sum(2(\\hat{y}-y)\\cdot\\frac{\\partial \\hat{y}}{\\partial\\vec{w}})\\\\\n",
    "    &=\\frac{2}{n}\\sum(\\hat{y}-y)\\vec{x}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial J}{\\partial b}&=\\frac{\\partial}{\\partial b}\\left(\\frac{1}{n}\\sum(\\hat{y}-y)^2\\right)\\\\\n",
    "    &=\\frac{1}{n}\\sum(2(\\hat{y}-y)\\cdot\\frac{\\partial\\hat{y}}{\\partial b})\\\\\n",
    "    &=\\frac{2}{n}\\sum(\\hat{y}-y)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updates\n",
    "\n",
    "$$\\vec{w}=\\vec{w}-\\alpha\\left(\\frac{2}{n}\\sum(\\hat{y}-y)\\vec{x}\\right)$$\n",
    "$$b=b-\\alpha\\left(\\frac{2}{n}\\sum(\\hat{y}-y)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal solution to the linear regression problem can be found by using normal equation:\n",
    "$$\\vec{w}=(X^TX)^{-1}X^T\\vec{y}.$$\n",
    "However, it is slower and computationally more expensive as the data gets larger."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
